{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>Fake News Detection with Basic NLP and ML Models</center></h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Fake news detection is an important classification problem in machine learning community. Not only that, there is a huge demand to curb the spread of fake news in recent years. In this article, we present the implementation of fake news detection with multiple ML models. Note that, this article gives a very simple picture of fake news detection for beginners and hence no way comparable to top-notch models.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Steps involved in fake news detection can be described as below. <center>Background Information --- Data Pre-processing --- Model Building<center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**1. Background Information :** Research suggests that fake news articles typically have longer titles and their contents are repetitive in nature.<br>\n**2. Data Pre-Processing :** Based on the hypothesis, we pre-processed the data so as to use number of words in title and count of words in text &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp; as features. (Using CountVectorizer)<br>\n**3. Model Building :** Multiple machine learning models (Logistic Regression, Random Forest, Light Gradient Boosting etc.) were built and &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;hyperparameters were tuned.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"So, let's get started.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing Libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport pandas as pd\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.decomposition import TruncatedSVD\n\n\n!pip install -q wordcloud\nimport wordcloud\n\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('punkt')\n%load_ext autoreload\n%autoreload 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Pre-processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/fake-news-dataset/news.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'].value_counts()   # No class imbalance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.rename(columns = {'Unnamed: 0': 'Id'})     # Replacing the unnamed column with 'Id'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating new feature : Number of words in news 'title'\n\ndef num_words(string):\n    words = string.split()\n    return len(words)\n\ndata['num_word_title'] = data['title'].apply(num_words)\n\nprint(data.groupby(data['label']).mean())\n\ncols = ['title','num_word_title','text', 'label']\ndata = data[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['num_word_title']>25].groupby('label').count()    # This clearly shows if title length is more than 25, it's highly likely to be a fake news.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1. Train-Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to split data into train and test set\ndef train_test_split(df, train_percent=.80, validate_percent=.20, seed=10):\n    np.random.seed(seed)\n    perm = np.random.permutation(df.index)\n    m = len(df.index)\n    train_end = int(train_percent * m)\n    train = df.iloc[perm[:train_end]]\n    test = df.iloc[perm[train_end:]]\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(data[['num_word_title','text','label']], seed = 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Feature Generation (CountVectorizer)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Necessary for lemmatization\nclass LemmaTokenizer:\n    def __init__(self):\n        self.wnl = WordNetLemmatizer()\n    def __call__(self, doc):\n        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CountVectorizer\ncount_vectorizer = CountVectorizer(stop_words = 'english', tokenizer=LemmaTokenizer(), \n                                   ngram_range = (1,2), dtype = np.uint8)\n\ncount_train = count_vectorizer.fit_transform(train['text'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_test = count_vectorizer.transform(test['text'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nWe won't use TfidfVectorizer. However, if any one wants to use it, pre-processing step is similar.\n# TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize a TfidfVectorizer object: tfidf_vectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.7, tokenizer=LemmaTokenizer(), \n                                   ngram_range = (1,2), dtype = np.float32)\n\n# Transform the training data: tfidf_train \ntfidf_train = tfidf_vectorizer.fit_transform(train['text'].values)\n# Transform the test data\ntfidf_test = tfidf_vectorizer.transform(test['text'].values)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3. Latent Semantic Analysis (For Dimensionality Reduction)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsa_count = TruncatedSVD(n_components = 400, random_state = 20)\nlsa_count.fit(count_train)\nprint(lsa_count.explained_variance_ratio_.sum())          # Explained_variance = 84.66 %","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count_train_df = pd.DataFrame.sparse.from_spmatrix(count_train, columns = count_vectorizer.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_train_lsa = pd.DataFrame(lsa_count.transform(count_train))\ncount_test_lsa = pd.DataFrame(lsa_count.transform(count_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding number of words in news title as a feature\ncount_train_lsa['num_word_title'] = train['num_word_title'] / data['num_word_title'].max()\ncount_test_lsa['num_word_title'] = test['num_word_title'] / data['num_word_title'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_train_lsa.fillna(count_train_lsa.mean(), inplace = True)\ncount_test_lsa.fillna(count_test_lsa.mean(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_train_lsa.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Model Building","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Naive-Bayes Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trying out with Gaussian Naive Bayes and CountVectorizer model\n# Here we are iteratively doing grid search with different hyperparameters in an informed manner.\n# params_NB = {'var_smoothing' : [1e-1, 1, 40, 100, 1000]} # var_smoothing = 40 gives the best result.\nparams_NB = {'var_smoothing' : [20,25,30,35,40,45, 50, 55, 60, 80]} # var_smoothing = 55 gives the best result.\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_NB = GridSearchCV(estimator = GaussianNB(),param_grid = params_NB, cv = 3, refit = True, scoring = 'accuracy', n_jobs = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_NB.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_NB.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_NB.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_NB = clf_NB.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(test['label'], test_count_pred_NB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_NB = confusion_matrix(test['label'], test_count_pred_NB, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_NB/ np.sum(cm_NB),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_NB = classification_report(test['label'], test_count_pred_NB, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_NB = pd.DataFrame(count_report_NB).transpose()\ncount_report_NB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_LR = {'C' : [10, 5, 1,0.7, 0.5,0.3]}\n\n# C = 0.5 gives the best result after Grid Search.\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_LR = GridSearchCV(estimator = LogisticRegression(class_weight = 'balanced', random_state = 6),param_grid = params_LR, \n                      cv = 3, refit = True, scoring = 'accuracy', n_jobs = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"clf_LR.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_LR.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_LR.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_LR = clf_LR.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_LR = confusion_matrix(test['label'], test_count_pred_LR, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_LR/ np.sum(cm_LR),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_LR = classification_report(test['label'], test_count_pred_LR, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_LR = pd.DataFrame(count_report_LR).transpose()\ncount_report_LR","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3. K-Nearest Neighbor Method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we are iteratively doing grid search with different hyperparameters in an informed manner.\n# params_knn = {'n_neighbors' : [2, 4, 8, 16] } # We obtain 4 as the best hyperparameter.\nparams_knn = {'n_neighbors' : [3,4,5,6,7] }     # 5 is the final tuned hyperparameter.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_knn = GridSearchCV(estimator = KNeighborsClassifier(algorithm = 'ball_tree'), param_grid = params_knn, \n                       scoring = 'accuracy', n_jobs = 4, cv = 3, refit = True, verbose = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_knn.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_knn.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_knn.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_knn = clf_knn.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_knn = confusion_matrix(test['label'], test_count_pred_knn, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_knn/ np.sum(cm_knn),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_knn = classification_report(test['label'], test_count_pred_knn, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_knn = pd.DataFrame(count_report_knn).transpose()\ncount_report_knn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.4. Support Vector Machine Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we are iteratively doing grid search with different hyperparameters in an informed manner.\n# params_svc = {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'], 'C' : [0.1, 1, 50]} # 'rbf' and 50 give the best combination\n# params_svc = {'kernel' : ['rbf', 'sigmoid'], 'C' : [10, 30, 50,100]}  # 100 and 'rbf' give the best combination.\nparams_svc = {'kernel' : ['rbf', 'sigmoid'], 'C' : [100, 150, 200]}   # 100 and 'rbf' give the best combination.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svc = GridSearchCV(estimator = SVC(class_weight = 'balanced', random_state = 6), param_grid = params_svc, \n                       scoring = 'accuracy', n_jobs = 4, cv = 3, refit = True, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svc.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svc.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_svc = clf_svc.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_svc = confusion_matrix(test['label'], test_count_pred_svc, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_svc/ np.sum(cm_svc),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_svc = classification_report(test['label'], test_count_pred_svc, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_svc = pd.DataFrame(count_report_svc).transpose()\ncount_report_svc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.5. Linear Discriminant Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_LDA = {'solver' : ['svd', 'lsqr', 'eigen'], 'shrinkage' : ['auto', None]}\n\n# (shrinkage = None and solver = svd) give the best result.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_LDA = GridSearchCV(estimator = LinearDiscriminantAnalysis(), param_grid = params_LDA, scoring = 'accuracy', n_jobs = 4,\n                       cv = 3, refit = True, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_LDA.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_LDA.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_LDA.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_LDA = clf_LDA.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_LDA = confusion_matrix(test['label'], test_count_pred_LDA, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_LDA/ np.sum(cm_LDA),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_LDA = classification_report(test['label'], test_count_pred_LDA, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_LDA = pd.DataFrame(count_report_LDA).transpose()\ncount_report_LDA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.6. Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_dt = {'criterion' : ['entropy'], 'min_samples_split' : [2, 4, 8, 16, 32], \n             'min_samples_leaf' : [1,2,4,8],'max_depth' : [4, 7, 10], 'max_features' : ['sqrt', None],  'class_weight' : ['balanced']}\n\n# (max_depth = 7, min_samples_leaf = 4, min_samples_split = 32, max_features = None) give the best result.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_dt = GridSearchCV(estimator = DecisionTreeClassifier(random_state = 7), param_grid = params_dt, \n                      scoring = 'accuracy', n_jobs = 4, cv = 3, refit = True, verbose = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_dt.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_dt.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_dt.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_dt = clf_dt.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_dt = confusion_matrix(test['label'], test_count_pred_dt, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_dt/ np.sum(cm_dt),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_dt = classification_report(test['label'], test_count_pred_dt, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_dt = pd.DataFrame(count_report_dt).transpose()\ncount_report_dt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.7. Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_RF = {'n_estimators' : [400, 1000, 1600], 'criterion' : ['entropy'], 'min_samples_split' : [2, 4, 8, 16], \n             'min_samples_leaf' : [1,2], 'class_weight' : ['balanced']}  \n\n# (min_samples_leaf = 1, min_samples_split = 4 , n_estimators = 1000) give the best result.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_RF = GridSearchCV(estimator = RandomForestClassifier(oob_score = True, random_state = 7), param_grid = params_RF, \n                      scoring = 'accuracy', n_jobs = 4, cv = 3, refit = True, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_RF.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_RF.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_RF.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_RF = clf_RF.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_RF = confusion_matrix(test['label'], test_count_pred_RF, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_RF/ np.sum(cm_RF),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_RF = classification_report(test['label'], test_count_pred_RF, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_RF = pd.DataFrame(count_report_RF).transpose()\ncount_report_RF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.8. AdaBoost Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we are iteratively doing grid search with different hyperparameters in an informed manner.\n# params_ada = {'n_estimators' : [50, 100, 500], 'learning_rate' : [1, 0.3]} # 500 and 1 give the best combination.\nparams_ada = {'n_estimators' : [500, 1000, 1500, 2000], 'learning_rate' : [1]} \n# (n_estimators = 1500, learning_rate = 1) is the best combination.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_ada = GridSearchCV(estimator = AdaBoostClassifier(random_state = 8), param_grid = params_ada, \n                       scoring = 'accuracy', n_jobs = 4, cv = 3, refit = True, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_ada.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_ada.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_ada.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_ada = clf_ada.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_ada = confusion_matrix(test['label'], test_count_pred_ada, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_ada/ np.sum(cm_ada),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_ada = classification_report(test['label'], test_count_pred_ada, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_ada = pd.DataFrame(count_report_ada).transpose()\ncount_report_ada","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.9. Light Gradient Boosting Method ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we are iteratively doing grid search with different hyperparameters in an informed manner.\n#params_lgb = {'n_estimators' : [100, 400, 800], 'learning_rate' : [0.03, 0.1], 'min_child_samples' : [4, 12, 24]}\n# 800, 0.1 , 4 are the best ones.\n#params_lgb = {'n_estimators' : [1200, 2400], 'learning_rate' : [ 0.1], 'min_child_samples' : [2,4]}  \n# (n_estimators = 2400 and min_child_samples = 2) are the best ones.\n# Let's just try with n_estimators 3600.\nparams_lgb = {'n_estimators' : [3600], 'learning_rate' : [ 0.1], 'min_child_samples' : [1,2]} \n# (n_estimators = 3600, learning_rate = 0.1, min_child_samples = 1) perform best.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_lgb = GridSearchCV(estimator = lgb.LGBMClassifier(), param_grid = params_lgb, scoring = 'accuracy', n_jobs = 4,\n                       cv = 3, refit = True, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_lgb.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_lgb.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clf_lgb.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_lgb = clf_lgb.predict(count_test_lsa)   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_lgb = confusion_matrix(test['label'], test_count_pred_lgb, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_lgb/ np.sum(cm_lgb),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_lgb = classification_report(test['label'], test_count_pred_lgb, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_lgb = pd.DataFrame(count_report_lgb).transpose()\ncount_report_lgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.10. CatBoosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import catboost as cb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_cat = {'n_estimators' : [800,1000,2000] }   #  1000 is the best one","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_cat = GridSearchCV(estimator = cb.CatBoostClassifier(task_type = 'GPU', learning_rate = 0.2, max_depth = 6), param_grid = params_cat,\n                       scoring = 'accuracy', n_jobs = 1, cv = 3, refit = True, verbose = 2 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"clf_cat.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_cat.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_cat = clf_cat.predict(count_test_lsa)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_cat = confusion_matrix(test['label'], test_count_pred_cat, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_cat/ np.sum(cm_cat),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_cat = classification_report(test['label'], test_count_pred_cat, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_cat = pd.DataFrame(count_report_cat).transpose()\ncount_report_cat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.11. TPOT Classifier (Genetic Algorithm)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tpot import TPOTClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_tpot = TPOTClassifier(generations = 6, population_size = 6, random_state = 3, cv = 2, n_jobs = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_tpot.fit(count_train_lsa, train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_tpot.fitted_pipeline_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_count_pred_tpot = clf_tpot.predict(count_test_lsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_tpot = confusion_matrix(test['label'], test_count_pred_tpot, labels = ['FAKE', 'REAL'])\nsns.heatmap(cm_tpot/ np.sum(cm_tpot),fmt='.2%', annot=True, cmap = 'Blues', xticklabels = ['FAKE', 'REAL'], yticklabels = ['FAKE', 'REAL'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncount_report_tpot = classification_report(test['label'], test_count_pred_tpot, labels = ['FAKE','REAL'], output_dict = True)\ncount_report_tpot = pd.DataFrame(count_report_tpot).transpose()\ncount_report_tpot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}